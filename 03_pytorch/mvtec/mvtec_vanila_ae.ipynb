{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1902bff4",
   "metadata": {},
   "source": [
    "## MVTec Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51babca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_msssim import ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5f86e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "class MVTec(Dataset):\n",
    "    def __init__(self, data_dir, categories, split, transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for category in categories:\n",
    "            category_path = os.path.join(data_dir, category, split)\n",
    "            if split == \"train\":\n",
    "                label = 0\n",
    "                for path in glob(os.path.join(category_path, \"good\", \"*.png\")):\n",
    "                    self.image_paths.append(path)\n",
    "                    self.labels.append(label)\n",
    "            else:\n",
    "                for subfolder in os.listdir(category_path):\n",
    "                    label = 0 if subfolder == \"good\" else 1\n",
    "                    for path in glob(os.path.join(category_path, subfolder, \"*.png\")):\n",
    "                        self.image_paths.append(path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        # return {\"image\": image, \"label\": label, \"path\": path}\n",
    "        return {\"image\": image, \"label\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efbb941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modeling\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1):\n",
    "        super().__init__()\n",
    "        self.deconv_block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.deconv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b842c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanilaEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, latent_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            ConvBlock(in_channels, 32),\n",
    "            ConvBlock(32, 64),\n",
    "            ConvBlock(64, 128),\n",
    "            ConvBlock(128, 256),\n",
    "            ConvBlock(256, 512),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.conv_blocks(x)\n",
    "        pooled = self.pool(features)\n",
    "        pooled = pooled.view(pooled.size(0), -1)\n",
    "        latent = self.fc(pooled)\n",
    "        return latent, features\n",
    "\n",
    "\n",
    "class VanilaDecoder(nn.Module):\n",
    "    def __init__(self, out_channels=3, latent_dim=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(latent_dim, 512*8*8)\n",
    "        self.unflatten = nn.Unflatten(1, (512, 8, 8))\n",
    "        self.deconv_blocks = nn.Sequential(\n",
    "            DeconvBlock(512, 256),\n",
    "            DeconvBlock(256, 128),\n",
    "            DeconvBlock(128, 64),\n",
    "            DeconvBlock(64, 32),\n",
    "            nn.ConvTranspose2d(32, out_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, latent):\n",
    "        x = self.fc(latent)                     # (B, 512 * 8 * 8)\n",
    "        x = self.unflatten(x)                   # (B, 512, 8, 8)\n",
    "        reconstructed = self.deconv_blocks(x)\n",
    "        return reconstructed\n",
    "\n",
    "class VanilaAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent, features = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5585dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trainer\n",
    "def train(model, data_loader, loss_fn, optimizer, metrics={}):\n",
    "    device = next(model.parameters()).device\n",
    "    model.train()\n",
    "\n",
    "    functions = {\"loss\": loss_fn}\n",
    "    functions.update(metrics)\n",
    "    results = {name: 0.0 for name in functions.keys()}\n",
    "\n",
    "    with tqdm(data_loader, desc=\"Training\", leave=False, file=sys.stdout,\n",
    "              dynamic_ncols=True,\n",
    "              ncols=100, ascii=True) as pbar:\n",
    "        for cnt, data in enumerate(pbar):\n",
    "            images = data['image'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            normal_mask = labels == 0\n",
    "            if not normal_mask.any():\n",
    "                continue\n",
    "\n",
    "            normal_images = images[normal_mask]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred, *_ = model(normal_images)\n",
    "            loss = loss_fn(pred, normal_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            results[\"loss\"] += loss.item()\n",
    "            for name, func in functions.items():\n",
    "                if name != \"loss\":\n",
    "                    results[name] += func(pred, normal_images).item()\n",
    "\n",
    "            pbar.set_postfix({k: f\"{v/(cnt + 1):.3f}\" for k, v in results.items()})\n",
    "\n",
    "    return {k: v/len(data_loader) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23820b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, loss_fn, metrics=None):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    functions = {\"loss\": loss_fn}\n",
    "    functions.update(metrics)\n",
    "    results = {name: 0.0 for name in functions.keys()}\n",
    "\n",
    "    with tqdm(data_loader, desc=\"Evaluation\", leave=False, file=sys.stdout,\n",
    "            dynamic_ncols=True,\n",
    "            ncols=100, ascii=True) as pbar:\n",
    "        for cnt, data in enumerate(pbar):\n",
    "            images = data['image'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            normal_mask = labels == 0\n",
    "            if not normal_mask.any():\n",
    "                continue\n",
    "\n",
    "            normal_images = images[normal_mask]\n",
    "            pred, *_ = model(normal_images)\n",
    "            loss = loss_fn(pred, normal_images)\n",
    "\n",
    "            results[\"loss\"] += loss.item()\n",
    "            for name, func in functions.items():\n",
    "                if name != \"loss\":\n",
    "                    results[name] += func(pred, normal_images).item()\n",
    "\n",
    "            pbar.set_postfix({k: f\"{v/(cnt + 1):.3f}\" for k, v in results.items()})\n",
    "\n",
    "    return {k: v/len(data_loader) for k, v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e79b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid(dataset, valid_ratio, seed=42):\n",
    "    data_size = len(dataset)\n",
    "    valid_size = int(data_size * valid_ratio)\n",
    "    train_size = data_size - valid_size\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    train_subset, valid_subset = random_split(dataset, [train_size, valid_size])\n",
    "    return train_subset.indices, valid_subset.indices\n",
    "\n",
    "def recon_loss(pred, target):\n",
    "    bce = nn.BCELoss()\n",
    "    return 0.5 * (1 - ssim(pred, target)) + 0.5 * bce(pred, target)\n",
    "\n",
    "def binary_accuracy(x_pred, x_true):\n",
    "    return torch.eq(x_pred.round(), x_true.round()).float().mean()\n",
    "\n",
    "def psnr(pred, target):\n",
    "    mse = nn.MSELoss()(pred, target)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 10 * torch.log10(1.0 ** 2 / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b27622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "img_size = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "## Augmentations\n",
    "train_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((img_size, img_size)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((img_size, img_size)),\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeed8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loaders\n",
    "data_dir = '/mnt/d/datasets/mvtec'\n",
    "# categories = ['bottle', 'cable', 'capsule', 'carpet', 'grid',\n",
    "#                 'hazelnut', 'leather', 'metal_nut', 'pill', 'screw',\n",
    "#                 'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n",
    "categories = ['bottle', 'grid', 'tile']\n",
    "\n",
    "train_dataset = MVTec(data_dir, categories, split=\"train\", transform=train_transform)\n",
    "valid_dataset = MVTec(data_dir, categories, split=\"train\", transform=test_transform)\n",
    "train_indices, valid_indices = split_train_valid(train_dataset, valid_ratio=0.2)\n",
    "\n",
    "train_dataset = Subset(train_dataset, train_indices)\n",
    "valid_dataset = Subset(valid_dataset, valid_indices)\n",
    "test_dataset  = MVTec(data_dir, categories, split=\"test\", transform=test_transform)\n",
    "\n",
    "kwargs = {\"num_workers\": 4, \"pin_memory\": True, \"drop_last\": True, \"persistent_workers\": True}\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, **kwargs)\n",
    "valid_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, **kwargs)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb5c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modeling\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = VanilaEncoder(in_channels=3, latent_dim=512)\n",
    "decoder = VanilaDecoder(out_channels=3, latent_dim=512)\n",
    "model = VanilaAutoEncoder(encoder, decoder).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "metrics = {\"mse\": nn.MSELoss(),\n",
    "        #    \"bce\": nn.BCELoss(),\n",
    "        #    \"acc\": binary_accuracy,\n",
    "           \"ssim\": ssim,\n",
    "           \"psnr\": psnr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b79c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1/10] loss=0.059, mse=0.059, ssim=0.995, psnr=12.457 | val_loss=0.051, val_mse=0.051, val_ssim=0.995, val_psnr=13.005 (19s)\n",
      "[Epoch  2/10] loss=0.039, mse=0.039, ssim=0.997, psnr=14.117 | val_loss=0.036, val_mse=0.036, val_ssim=0.997, val_psnr=14.488 (16s)\n",
      "[Epoch  3/10] loss=0.034, mse=0.034, ssim=0.997, psnr=14.716 | val_loss=0.034, val_mse=0.034, val_ssim=0.997, val_psnr=14.674 (19s)\n",
      "[Epoch  4/10] loss=0.033, mse=0.033, ssim=0.997, psnr=14.837 | val_loss=0.031, val_mse=0.031, val_ssim=0.997, val_psnr=15.068 (16s)\n",
      "[Epoch  5/10] loss=0.030, mse=0.030, ssim=0.997, psnr=15.190 | val_loss=0.028, val_mse=0.028, val_ssim=0.998, val_psnr=15.509 (16s)\n",
      "[Epoch  6/10] loss=0.027, mse=0.027, ssim=0.998, psnr=15.687 | val_loss=0.026, val_mse=0.026, val_ssim=0.998, val_psnr=15.921 (18s)\n",
      "[Epoch  7/10] loss=0.026, mse=0.026, ssim=0.998, psnr=15.812 | val_loss=0.025, val_mse=0.025, val_ssim=0.998, val_psnr=16.011 (16s)\n",
      "[Epoch  8/10] loss=0.025, mse=0.025, ssim=0.998, psnr=16.000 | val_loss=0.025, val_mse=0.025, val_ssim=0.998, val_psnr=15.981 (19s)\n",
      "[Epoch  9/10] loss=0.024, mse=0.024, ssim=0.998, psnr=16.152 | val_loss=0.024, val_mse=0.024, val_ssim=0.998, val_psnr=16.196 (16s)\n",
      "[Epoch 10/10] loss=0.024, mse=0.024, ssim=0.998, psnr=16.169 | val_loss=0.023, val_mse=0.023, val_ssim=0.998, val_psnr=16.395 (19s)\n",
      ">> Test: test_loss=0.006, test_mse=0.006, test_ssim=0.470, test_psnr=8.819                                 \n"
     ]
    }
   ],
   "source": [
    "## Training Loop\n",
    "history = {\"loss\": []}\n",
    "history.update({name: [] for name in metrics.keys()})\n",
    "history.update({f\"val_{name}\": [] for name in history.keys()})\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time()\n",
    "\n",
    "    ## Training\n",
    "    train_results = train(model, train_loader, loss_fn, optimizer, metrics=metrics)\n",
    "    train_desc = ', '.join([f\"{k}={v:.3f}\" for k, v in train_results.items()])\n",
    "\n",
    "    for name, value in train_results.items():\n",
    "        history[name].append(value)\n",
    "\n",
    "    ## Validation\n",
    "    valid_results = evaluate(model, valid_loader, loss_fn, metrics=metrics)\n",
    "    valid_desc = ', '.join([f\"val_{k}={v:.3f}\" for k, v in valid_results.items()])\n",
    "\n",
    "    for name, value in valid_results.items():\n",
    "        history[f\"val_{name}\"].append(value)\n",
    "\n",
    "    epoch_time = time() - start_time\n",
    "    print(f\"[Epoch {epoch:2d}/{num_epochs}] {train_desc} | {valid_desc} ({epoch_time:.0f}s)\")\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "test_results = evaluate(model, test_loader, loss_fn, metrics=metrics)\n",
    "test_desc = ', '.join([f\"test_{k}={v:.3f}\" for k, v in test_results.items()])\n",
    "print(f\">> Test: {test_desc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
