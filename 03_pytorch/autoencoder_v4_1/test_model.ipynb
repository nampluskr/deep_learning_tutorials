{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b77fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autoencoder import get_model\n",
    "from config import load_config, print_config\n",
    "from train import load_weights\n",
    "\n",
    "results_dir = \"/mnt/d/github/deep_learning_tutorials/03_pytorch/autoencoder_v4_1/results/unet_ae_bottle_default\"\n",
    "model_filename = \"unet_ae_bottle_default_model.pth\"\n",
    "config_filename = \"unet_ae_bottle_default_config.json\"\n",
    "\n",
    "config_path = os.path.join(results_dir, config_filename)\n",
    "config = load_config(config_path)\n",
    "\n",
    "model = get_model(model_type=\"unet_ae\")\n",
    "model_path = os.path.join(results_dir, model_filename)\n",
    "model = load_weights(model, model_path=model_path)\n",
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b016608d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mvtec import get_transforms, get_dataloaders\n",
    "\n",
    "train_transform, test_transform = get_transforms(\n",
    "    img_size=config.img_size,\n",
    "    normalize=config.normalize\n",
    ")\n",
    "train_loader, valid_loader, test_loader = get_dataloaders(\n",
    "    data_dir=config.data_dir,\n",
    "    category=config.category,\n",
    "    batch_size=config.batch_size,\n",
    "    valid_ratio=config.valid_ratio,\n",
    "    train_transform=train_transform,\n",
    "    test_transform=test_transform\n",
    ")\n",
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a342c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def denormalize(images, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    \"\"\"Denormalize images from ImageNet normalization back to [0, 1] range\"\"\"\n",
    "    device = images.device\n",
    "    mean = torch.tensor(mean).view(1, 3, 1, 1).to(device)\n",
    "    std = torch.tensor(std).view(1, 3, 1, 1).to(device)\n",
    "\n",
    "    # Denormalize: x = x_norm * std + mean\n",
    "    denorm_images = images * std + mean\n",
    "\n",
    "    # Clamp to [0, 1] range to ensure valid pixel values\n",
    "    return torch.clamp(denorm_images, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e4d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83,) (83,) 83\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def batch_mse(pred, target):\n",
    "    \"\"\"Compute Mean Squared Error for a batch of images\"\"\"\n",
    "    return torch.mean((pred - target)** 2, dim=[1, 2, 3])\n",
    "\n",
    "scores = []\n",
    "labels = []\n",
    "types = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "\n",
    "        batch_images = batch['image'].to(config.device)\n",
    "        batch_images = denormalize(batch_images)\n",
    "\n",
    "        batch_labels = batch['label']\n",
    "        batch_types = batch['defect_type']\n",
    "\n",
    "        reconstructed, _, _ = model(batch_images)\n",
    "        batch_scores = batch_mse(reconstructed, batch_images)\n",
    "        \n",
    "        scores.extend(batch_scores.cpu().numpy())\n",
    "        labels.extend(batch_labels.cpu().numpy())\n",
    "        types.extend(batch_types)\n",
    "\n",
    "scores = np.array(scores)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(scores.shape, labels.shape, len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39841269841269844,\n",
       " 0.7815537496157696,\n",
       " 0.30120481927710846,\n",
       " 1.0,\n",
       " 0.07936507936507936,\n",
       " 0.14705882352941177,\n",
       " 0.0004987909342162311)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import (roc_auc_score, \n",
    "    average_precision_score, f1_score, accuracy_score,\n",
    "    precision_score, recall_score)\n",
    "\n",
    "percentile = 95\n",
    "threshold = float(np.percentile(scores, percentile))\n",
    "predictions = (scores > threshold).astype(int)\n",
    "\n",
    "auroc = float(roc_auc_score(labels, scores))\n",
    "aupr = float(average_precision_score(labels, scores))\n",
    "accuracy = float(accuracy_score(labels, predictions))\n",
    "precision = float(precision_score(labels, predictions, zero_division=0))\n",
    "recall = float(recall_score(labels, predictions, zero_division=0))\n",
    "f1_score = float(f1_score(labels, predictions, zero_division=0))\n",
    "\n",
    "auroc, aupr, accuracy, precision, recall, f1_score, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75143bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39841269841269844,\n",
       " 0.7815537496157696,\n",
       " 0.14705882352941177,\n",
       " 0.30120481927710846,\n",
       " 0.0004987909342162311)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc, aupr, f1, acc, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53902a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
